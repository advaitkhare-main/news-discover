name: Update News JSON
on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

permissions:
  contents: write  # ‚Üê THIS FIXES GIT!

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Install feedparser
      run: pip3 install feedparser
    
    - name: Generate news.json
      run: |
        python3 << EOF
        import feedparser,json
        from datetime import datetime
        feeds=[("https://feeds.feedburner.com/ndtvnews-latest","india","NDTV"),
               ("https://feeds.bbci.co.uk/news/rss.xml","global","BBC"),
               ("https://venturebeat.com/category/ai/feed/","scitech","VentureBeat"),
               ("https://economictimes.indiatimes.com/markets/rssfeeds/1977021501.cms","finance","ET"),
               ("https://www.espncricinfo.com/rss/content/story/feeds/0.xml","sports","Cricinfo"),
               ("https://www.lokmat.com/rss/","marathi","Lokmat")]
        news=[]
        for url,cat,src in feeds:
            d=feedparser.parse(url)
            for e in d.entries[:6]:
                news.append({"category":cat,"title":e.title[:100],
                           "summary":getattr(e,"summary","")[:200],
                           "image":"https://picsum.photos/400/250?news","source":src,
                           "pubDate":getattr(e,"published",str(datetime.now())),
                           "link":getattr(e,"link","#"),"id":hash(e.link)})
        news.sort(key=lambda x:x["pubDate"],reverse=True)
        with open("docs/news.json","w") as f:
            json.dump(news[:40],f,indent=2)
        print(f"SAVED {len(news)} articles!")
        EOF
    
    - name: Commit changes
      uses: EndBug/add-and-commit@v9
      with:
        add: 'docs/news.json'
        message: "ü§ñ Fresh news {{ github.run_id }}"
